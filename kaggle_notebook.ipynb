{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dow_jones = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/indices/Dow_Jones.csv').to_dict(orient='records')\n",
    "nasdaq = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/indices/NASDAQ.csv').to_dict(orient='records')\n",
    "sp500 = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/indices/SP500.csv').to_dict(orient='records')\n",
    "\n",
    "stockAAPL = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/AAPL.csv').to_dict(orient='records')\n",
    "stockABBV = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/ABBV.csv').to_dict(orient='records')\n",
    "stockAXP = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/AXP.csv').to_dict(orient='records')\n",
    "stockBA = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/BA.csv').to_dict(orient='records')\n",
    "stockBOOT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/BOOT.csv').to_dict(orient='records')\n",
    "stockCALM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/CALM.csv').to_dict(orient='records')\n",
    "stockCAT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/CAT.csv').to_dict(orient='records')\n",
    "stockCL = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/CL.csv').to_dict(orient='records')\n",
    "stockCSCO = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/CSCO.csv').to_dict(orient='records')\n",
    "stockCVX = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/CVX.csv').to_dict(orient='records')\n",
    "stockDD = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/DD.csv').to_dict(orient='records')\n",
    "stockDENN = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/DENN.csv').to_dict(orient='records')\n",
    "stockDIS = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/DIS.csv').to_dict(orient='records')\n",
    "stockF = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/F.csv').to_dict(orient='records')\n",
    "stockGE = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/GE.csv').to_dict(orient='records')\n",
    "stockGM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/GM.csv').to_dict(orient='records')\n",
    "stockGS = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/GS.csv').to_dict(orient='records')\n",
    "stockHON = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/HON.csv').to_dict(orient='records')\n",
    "stockIBM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/IBM.csv').to_dict(orient='records')\n",
    "stockINTC = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/INTC.csv').to_dict(orient='records')\n",
    "stockIP = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/IP.csv').to_dict(orient='records')\n",
    "stockJNJ = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/JNJ.csv').to_dict(orient='records')\n",
    "stockJPM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/JPM.csv').to_dict(orient='records')\n",
    "stockKO = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/KO.csv').to_dict(orient='records')\n",
    "stockLMT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/LMT.csv').to_dict(orient='records')\n",
    "stockMA = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MA.csv').to_dict(orient='records')\n",
    "stockMCD = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MCD.csv').to_dict(orient='records')\n",
    "stockMG = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MG.csv').to_dict(orient='records')\n",
    "stockMMM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MMM.csv').to_dict(orient='records')\n",
    "stockMS = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MS.csv').to_dict(orient='records')\n",
    "stockMSFT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/MSFT.csv').to_dict(orient='records')\n",
    "stockNKE = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/NKE.csv').to_dict(orient='records')\n",
    "stockPEP = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/PEP.csv').to_dict(orient='records')\n",
    "stockPFE = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/PFE.csv').to_dict(orient='records')\n",
    "stockPG = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/PG.csv').to_dict(orient='records')\n",
    "stockRTX = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/RTX.csv').to_dict(orient='records')\n",
    "stockSO = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/SO.csv').to_dict(orient='records')\n",
    "stockT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/T.csv').to_dict(orient='records')\n",
    "stockTDW = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/TDW.csv').to_dict(orient='records')\n",
    "stockV = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/V.csv').to_dict(orient='records')\n",
    "stockVZ = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/VZ.csv').to_dict(orient='records')\n",
    "stockWFC = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/WFC.csv').to_dict(orient='records')\n",
    "stockWMT = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/WMT.csv').to_dict(orient='records')\n",
    "stockXELB = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/XELB.csv').to_dict(orient='records')\n",
    "stockXOM = pd.read_csv('/kaggle/input/stock-price-prediction-challenge/train/stocks/XOM.csv').to_dict(orient='records')\n",
    "\n",
    "dataset = [\n",
    "    dow_jones,\n",
    "    nasdaq,\n",
    "    sp500,\n",
    "    stockAAPL,\n",
    "    stockABBV,\n",
    "    stockAXP,\n",
    "    stockBA,\n",
    "    stockBOOT,\n",
    "    stockCALM,\n",
    "    stockCAT,\n",
    "    stockCL,\n",
    "    stockCSCO,\n",
    "    stockCVX,\n",
    "    stockDD,\n",
    "    stockDENN,\n",
    "    stockDIS,\n",
    "    stockF,\n",
    "    stockGE,\n",
    "    stockGM,\n",
    "    stockGS,\n",
    "    stockHON,\n",
    "    stockIBM,\n",
    "    stockINTC,\n",
    "    stockIP,\n",
    "    stockJNJ,\n",
    "    stockJPM,\n",
    "    stockKO,\n",
    "    stockLMT,\n",
    "    stockMA,\n",
    "    stockMCD,\n",
    "    stockMG,\n",
    "    stockMMM,\n",
    "    stockMS,\n",
    "    stockMSFT,\n",
    "    stockNKE,\n",
    "    stockPEP,\n",
    "    stockPFE,\n",
    "    stockPG,\n",
    "    stockRTX,\n",
    "    stockSO,\n",
    "    stockT,\n",
    "    stockTDW,\n",
    "    stockV,\n",
    "    stockVZ,\n",
    "    stockWFC,\n",
    "    stockWMT,\n",
    "    stockXELB,\n",
    "    stockXOM\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from data_reader import *\n",
    "\n",
    "\n",
    "def create_autoregression_dataset(ticker_data_list: list[dict], n_past_days: int = 5):\n",
    "    \"\"\"\n",
    "    为单个股票代码的时间序列数据创建自回归数据集。\n",
    "\n",
    "    参数:\n",
    "    ticker_data_list (list): 包含单个股票代码每日数据的字典列表。\n",
    "    n_past_days (int): 用于预测的过去天数。\n",
    "\n",
    "    返回:\n",
    "    tuple: (X, Y) X是输入特征，Y是标签。\n",
    "           X的形状是 (n_samples, n_past_days * n_features_per_day)\n",
    "           Y的形状是 (n_samples, n_features_per_day)\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_daily_features(day_data: dict):\n",
    "        open_price = day_data['Open']\n",
    "        high_diff = day_data['High'] - open_price\n",
    "        low_diff = day_data['Low'] - open_price\n",
    "        close_diff = day_data['Adjusted'] - open_price\n",
    "        volume = day_data['Volume']\n",
    "        return [open_price, high_diff, low_diff, close_diff, volume]\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    daily_features_list = []\n",
    "    for day_data in ticker_data_list:\n",
    "        # 确保所有必要字段都存在且为数字\n",
    "        try:\n",
    "            features = extract_daily_features(day_data)\n",
    "            daily_features_list.append(features)\n",
    "        except (TypeError, KeyError) as e:\n",
    "            print(f\"Skipping day due to missing or invalid data: {day_data.get('Date', 'Unknown Date')}, Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 2. 创建滑动窗口数据集\n",
    "    # 我们需要 n_past_days 用于输入，1天用于标签，所以总共需要 n_past_days + 1 天的数据\n",
    "    if len(daily_features_list) < n_past_days + 1:\n",
    "        return torch.tensor([]), torch.tensor([])  # 不足以创建任何样本\n",
    "\n",
    "    for i in range(len(daily_features_list) - n_past_days):\n",
    "        # 输入特征：前 n_past_days 天的数据\n",
    "        past_features = []\n",
    "        for j in range(n_past_days):\n",
    "            past_features.append(daily_features_list[i + j])\n",
    "        X.append(past_features)\n",
    "\n",
    "        # 标签：第 (n_past_days+1) 天的数据\n",
    "        Y.append(daily_features_list[i + n_past_days])\n",
    "\n",
    "    return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "\n",
    "_dataset = [{\n",
    "    'ticker': x[0]['Ticker'],\n",
    "    'data': create_autoregression_dataset(x, n_past_days=5)\n",
    "}for x in dataset]\n",
    "\n",
    "print('Tickers: ', [x['ticker'] for x in _dataset])\n",
    "\n",
    "\n",
    "def get_dataset(ticker: str, train_ratio: float = 0.95, batch_size: int = 16) -> tuple[DataLoader, DataLoader]:\n",
    "    _dataset_from_ticker = [x for x in _dataset if x['ticker'] == ticker][0]['data']\n",
    "    inputs = torch.stack([x for x in _dataset_from_ticker[0]])\n",
    "    labels = torch.stack([x for x in _dataset_from_ticker[1]])\n",
    "    dataset_size = len(labels)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    train_dataset = TensorDataset(inputs[:train_size], labels[:train_size])\n",
    "    valid_dataset = TensorDataset(inputs[train_size:], labels[train_size:])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, valid_loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78681997729e37c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deeplotx import AutoRegression\n",
    "model = AutoRegression(feature_dim=5, hidden_dim=128, recursive_layers=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49ad5e30a39fa477"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from data_preprocess import get_dataset\n",
    "\n",
    "batch_size = 16\n",
    "train_loader, valid_loader = get_dataset('AAPL', batch_size=batch_size)\n",
    "\n",
    "num_epochs = 10\n",
    "elastic_net_param = {'alpha': 1e-4, 'rho': 0.2}\n",
    "learning_rate = 2e-6\n",
    "train_loss_threshold = 0.\n",
    "valid_loss_threshold = 0.\n",
    "criterion = nn.MSELoss()\n",
    "optim = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_texts, batch_labels in train_loader:\n",
    "        if batch_texts.shape[0] != batch_size:\n",
    "            continue\n",
    "        outputs = model.forward(batch_texts, model.initial_state(batch_size=batch_size))[0]\n",
    "        loss = criterion(outputs, batch_labels) + model.elastic_net(alpha=elastic_net_param['alpha'], rho=elastic_net_param['rho'])\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 3 == 0:\n",
    "        total_valid_loss = 0.0\n",
    "        for batch_texts, batch_labels in valid_loader:\n",
    "            if batch_texts.shape[0] != batch_size:\n",
    "                continue\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                outputs = model.forward(batch_texts, model.initial_state(batch_size=batch_size))[0]\n",
    "                loss = criterion(outputs, batch_labels) + model.elastic_net(alpha=elastic_net_param['alpha'], rho=elastic_net_param['rho'])\n",
    "                total_valid_loss += loss.item()\n",
    "                model.train()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {total_loss:.4f} | \"\n",
    "              f\"Valid Loss: {total_valid_loss:.4f}\")\n",
    "        if total_valid_loss <= valid_loss_threshold:\n",
    "            break\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {total_loss:.4f}\")\n",
    "    if total_loss <= train_loss_threshold:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7e2872477ccb1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_loader_large, test_loader_small = get_dataset('GSPC', batch_size=batch_size)\n",
    "total_eval_loss = 0.0\n",
    "for batch_texts, batch_labels in test_loader_large:\n",
    "    if batch_texts.shape[0] != batch_size:\n",
    "        continue\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model.forward(batch_texts, model.initial_state(batch_size=batch_size))[0]\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        total_eval_loss += loss.item()\n",
    "        model.train()\n",
    "print(f\"Eval Loss: {total_eval_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8337f171ef6e6bd0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
